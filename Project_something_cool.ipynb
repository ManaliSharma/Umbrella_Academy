{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tweepy\n",
    "import csv\n",
    "\n",
    "twitter_cred = dict()\n",
    "\n",
    "twitter_cred['CONSUMER_KEY'] = '17XHiftb4Iu5hVAIh4NacWj9S'\n",
    "twitter_cred['CONSUMER_SECRET'] = '8xAXhFsfnkiFjSFO5THqRO5J8x8lKSzC9J2GNPUSY7ZPb5z6Qv'\n",
    "twitter_cred['ACCESS_KEY'] = '1392379572-FInzXaziEqyNCGc8jqtU9LwnFFlHYRpjoihZpiX'\n",
    "twitter_cred['ACCESS_SECRET'] = 'JBDveSiUU6aXpwx8QkxYhXloDr9DyHn7ocqrqgWqwqctw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('twitter_credentials.json', 'w') as secret_info:\n",
    "    json.dump(twitter_cred, secret_info, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('twitter_credentials.json') as cred_data:\n",
    "    info = json.load(cred_data)\n",
    "    consumer_key = info['CONSUMER_KEY']\n",
    "    consumer_secret = info['CONSUMER_SECRET']\n",
    "    access_key = info['ACCESS_KEY']\n",
    "    access_secret = info['ACCESS_SECRET']\n",
    "\n",
    "# Create the api endpoint\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of tweets that you want to extract- 10\n"
     ]
    }
   ],
   "source": [
    "maximum_number_of_tweets_to_be_extracted = \\\n",
    "int(input('Enter the number of tweets that you want to extract- '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the hashtag you want to scrape- Datascience\n"
     ]
    }
   ],
   "source": [
    "hashtag = input('Enter the hashtag you want to scrape- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "\n",
    "def handle_emojis(tweet):\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "    tweet = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', tweet)\n",
    "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "    tweet = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' EMO_POS ', tweet)\n",
    "    # Love -- <3, :*\n",
    "    tweet = re.sub(r'(<3|:\\*)', ' EMO_POS ', tweet)\n",
    "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "    tweet = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', tweet)\n",
    "    # Sad -- :-(, : (, :(, ):, )-:\n",
    "    tweet = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', tweet)\n",
    "    # Cry -- :,(, :'(, :\"(\n",
    "    tweet = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    processed_tweet = []\n",
    "    # Replaces URLs with the word URL\n",
    "    tweet = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', ' URL ', tweet)\n",
    "    # Replace @handle with the word USER_MENTION\n",
    "    tweet = re.sub(r'@[\\S]+', 'USER_MENTION', tweet)\n",
    "    # Replaces #hashtag with hashtag\n",
    "    tweet = re.sub(r'#(\\S+)', r' \\1 ', tweet)\n",
    "    # Remove RT (retweet)\n",
    "    tweet = re.sub(r'\\brt\\b', '', tweet)\n",
    "    # Replace 2+ dots with space\n",
    "    tweet = re.sub(r'\\.{2,}', ' ', tweet)\n",
    "    # Strip space, \" and ' from tweet\n",
    "    tweet = tweet.strip(' \"\\'')\n",
    "    # Replace emojis with either EMO_POS or EMO_NEG\n",
    "    tweet = handle_emojis(tweet)\n",
    "    # Replace multiple spaces with a single space\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    words = tweet.split()\n",
    "\n",
    "    for word in words:\n",
    "        word = preprocess_word(word)\n",
    "        if is_valid_word(word):\n",
    "            if use_stemmer:\n",
    "                word = str(porter_stemmer.stem(word))\n",
    "            processed_tweet.append(word)\n",
    "\n",
    "    return ' '.join(processed_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 10 tweets with hashtag #Datascience\n"
     ]
    }
   ],
   "source": [
    "all_the_tweets = [] \n",
    "with open('output_json.json', 'w') as outfile:\n",
    "        \n",
    "    for tweet in tweepy.Cursor(api.search, q='#' + hashtag,rpp=100).items(maximum_number_of_tweets_to_be_extracted):\n",
    "        \n",
    "        if (not tweet.retweeted) :\n",
    "            \n",
    "            json.dump(tweet._json, outfile, indent=2) \n",
    "            outfile.write('\\n')\n",
    "            all_the_tweets.append(tweet)\n",
    "    #with open('tweets_with_hashtag_' + hashtag + '.txt', 'a') as the_file:\n",
    "        #the_file.write(str(tweet.text.encode('utf-8')) + '\\n')\n",
    "    #data=process_or_store(tweet._json)\n",
    "    #get_tweets()\n",
    "      \n",
    "\n",
    "print ('Extracted ' + str(maximum_number_of_tweets_to_be_extracted) + ' tweets with hashtag #' + hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "outtweets = [[tweet.id_str, tweet.created_at,tweet.text.encode('utf-8'),tweet.user.name,tweet.user.screen_name,tweet.user.friends_count,tweet.user.followers_count,tweet.retweet_count,tweet.favorite_count] for tweet in all_the_tweets]\n",
    "  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('_tweets.csv', 'w', encoding='utf8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id', 'created_at', 'text','user','screen_name','friends_count','followers_count','retweet_count','favorite_count'])\n",
    "    \n",
    "    writer.writerows(outtweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset=pd.read_csv('_tweets.csv',encoding=\"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1114756842746523648</td>\n",
       "      <td>2019-04-07 05:08:37</td>\n",
       "      <td>b'Artificial intelligence in Australia needs t...</td>\n",
       "      <td>Iain Brown, PhD</td>\n",
       "      <td>IainLJBrown</td>\n",
       "      <td>146618</td>\n",
       "      <td>148392</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1114756799964557312</td>\n",
       "      <td>2019-04-07 05:08:26</td>\n",
       "      <td>b\"RT @chidambara09: See Someone's Facebook and...</td>\n",
       "      <td>TechnoJeder IoT</td>\n",
       "      <td>IoT_Technojeder</td>\n",
       "      <td>29</td>\n",
       "      <td>717</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1114756760252715009</td>\n",
       "      <td>2019-04-07 05:08:17</td>\n",
       "      <td>b'Welcome to my blog!\\nhttps://t.co/EUfeo0ESwR...</td>\n",
       "      <td>Makoto Kyougoku</td>\n",
       "      <td>mk76e</td>\n",
       "      <td>361</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1114756587070152704</td>\n",
       "      <td>2019-04-07 05:07:36</td>\n",
       "      <td>b'32 Statistical Concepts Explained in Simple ...</td>\n",
       "      <td>Daniel Bastos ð§ð·</td>\n",
       "      <td>danielbastos</td>\n",
       "      <td>1259</td>\n",
       "      <td>1899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1114756500256374784</td>\n",
       "      <td>2019-04-07 05:07:15</td>\n",
       "      <td>b\"RT @chidambara09: See Someone's Facebook and...</td>\n",
       "      <td>Chris Chua</td>\n",
       "      <td>theChrisChua</td>\n",
       "      <td>222</td>\n",
       "      <td>1939</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1114756842746523648  2019-04-07 05:08:37   \n",
       "1  1114756799964557312  2019-04-07 05:08:26   \n",
       "2  1114756760252715009  2019-04-07 05:08:17   \n",
       "3  1114756587070152704  2019-04-07 05:07:36   \n",
       "4  1114756500256374784  2019-04-07 05:07:15   \n",
       "\n",
       "                                                text                    user  \\\n",
       "0  b'Artificial intelligence in Australia needs t...         Iain Brown, PhD   \n",
       "1  b\"RT @chidambara09: See Someone's Facebook and...         TechnoJeder IoT   \n",
       "2  b'Welcome to my blog!\\nhttps://t.co/EUfeo0ESwR...         Makoto Kyougoku   \n",
       "3  b'32 Statistical Concepts Explained in Simple ...  Daniel Bastos ð§ð·   \n",
       "4  b\"RT @chidambara09: See Someone's Facebook and...              Chris Chua   \n",
       "\n",
       "       screen_name  friends_count  followers_count  retweet_count  \\\n",
       "0      IainLJBrown         146618           148392              1   \n",
       "1  IoT_Technojeder             29              717              2   \n",
       "2            mk76e            361              215              0   \n",
       "3     danielbastos           1259             1899              0   \n",
       "4     theChrisChua            222             1939              2   \n",
       "\n",
       "   favorite_count  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hash_tags(s):\n",
    "    my_set=set(part[1:] for part in s.split() if part.startswith('#'))\n",
    "    my_list=list(my_set)\n",
    "    return(my_list)\n",
    "\n",
    "#dataset['Hashtags']=dataset['text'].apply(lambda row: extract_hash_tags(row))\n",
    "\n",
    "#x=dataset['text'].apply(lambda row: extract_hash_tags(row))\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "for list in x:\n",
    "    for x in list:\n",
    "        #z=set()\n",
    "        #z=z.union(i)\n",
    "        print(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "s={1,2}\n",
    "set_1={3,4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_ignore_order(a, b):\n",
    "    \"\"\" Use only when elements are neither hashable nor sortable! \"\"\"\n",
    "    unmatched = list(b)\n",
    "    for element in a:\n",
    "        try:\n",
    "            unmatched.remove(element)\n",
    "        except ValueError:\n",
    "            return False\n",
    "    return not unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataset=dataset.drop(['text_1'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hashtags(x):\n",
    "    if '#' in x:\n",
    "        return str(x.replace('#',''))\n",
    "        \n",
    "dataset['TextNoHashtags']=dataset['text'].apply(remove_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>TextNoHashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1114756842746523648</td>\n",
       "      <td>2019-04-07 05:08:37</td>\n",
       "      <td>b'Artificial intelligence in Australia needs t...</td>\n",
       "      <td>Iain Brown, PhD</td>\n",
       "      <td>IainLJBrown</td>\n",
       "      <td>146618</td>\n",
       "      <td>148392</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1114756799964557312</td>\n",
       "      <td>2019-04-07 05:08:26</td>\n",
       "      <td>b\"RT @chidambara09: See Someone's Facebook and...</td>\n",
       "      <td>TechnoJeder IoT</td>\n",
       "      <td>IoT_Technojeder</td>\n",
       "      <td>29</td>\n",
       "      <td>717</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1114756760252715009</td>\n",
       "      <td>2019-04-07 05:08:17</td>\n",
       "      <td>b'Welcome to my blog!\\nhttps://t.co/EUfeo0ESwR...</td>\n",
       "      <td>Makoto Kyougoku</td>\n",
       "      <td>mk76e</td>\n",
       "      <td>361</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'Welcome to my blog!\\nhttps://t.co/EUfeo0ESwR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1114756587070152704</td>\n",
       "      <td>2019-04-07 05:07:36</td>\n",
       "      <td>b'32 Statistical Concepts Explained in Simple ...</td>\n",
       "      <td>Daniel Bastos ð§ð·</td>\n",
       "      <td>danielbastos</td>\n",
       "      <td>1259</td>\n",
       "      <td>1899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'32 Statistical Concepts Explained in Simple ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1114756500256374784</td>\n",
       "      <td>2019-04-07 05:07:15</td>\n",
       "      <td>b\"RT @chidambara09: See Someone's Facebook and...</td>\n",
       "      <td>Chris Chua</td>\n",
       "      <td>theChrisChua</td>\n",
       "      <td>222</td>\n",
       "      <td>1939</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1114756842746523648  2019-04-07 05:08:37   \n",
       "1  1114756799964557312  2019-04-07 05:08:26   \n",
       "2  1114756760252715009  2019-04-07 05:08:17   \n",
       "3  1114756587070152704  2019-04-07 05:07:36   \n",
       "4  1114756500256374784  2019-04-07 05:07:15   \n",
       "\n",
       "                                                text                    user  \\\n",
       "0  b'Artificial intelligence in Australia needs t...         Iain Brown, PhD   \n",
       "1  b\"RT @chidambara09: See Someone's Facebook and...         TechnoJeder IoT   \n",
       "2  b'Welcome to my blog!\\nhttps://t.co/EUfeo0ESwR...         Makoto Kyougoku   \n",
       "3  b'32 Statistical Concepts Explained in Simple ...  Daniel Bastos ð§ð·   \n",
       "4  b\"RT @chidambara09: See Someone's Facebook and...              Chris Chua   \n",
       "\n",
       "       screen_name  friends_count  followers_count  retweet_count  \\\n",
       "0      IainLJBrown         146618           148392              1   \n",
       "1  IoT_Technojeder             29              717              2   \n",
       "2            mk76e            361              215              0   \n",
       "3     danielbastos           1259             1899              0   \n",
       "4     theChrisChua            222             1939              2   \n",
       "\n",
       "   favorite_count                                     TextNoHashtags  \n",
       "0               0                                               None  \n",
       "1               0                                               None  \n",
       "2               0  b'Welcome to my blog!\\nhttps://t.co/EUfeo0ESwR...  \n",
       "3               0  b'32 Statistical Concepts Explained in Simple ...  \n",
       "4               0                                               None  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'set'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-746ac3c243fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hashtags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1665\u001b[0m         \u001b[0mCategories\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \"\"\"\n\u001b[0;32m-> 1667\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munique1d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.unique\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'set'"
     ]
    }
   ],
   "source": [
    "dataset['Hashtags'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-110-222f4522150f>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-110-222f4522150f>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    outfile2.write('\\n')\u001b[0m\n\u001b[0m                        \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "''''with open('output_json_filtered.json', 'w') as outfile2:\n",
    "        filtered_keys = [\"tweet.created_at\", \"tweet.id\", \"tweet.user.followers_count\", \"tweet.user.friends_count\", \"tweet.retweet_count\", \"tweet.favorite_count\", \"tweet.text\"]\n",
    "        for filtered_keys in tweet:\n",
    "            json.dump(filtered_keys._json, outfile2, indent=2) \n",
    "            outfile2.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "citation:\n",
    "https://github.com/abdulfatir/twitter-sentiment-analysis/blob/master/code/preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystring=\"b'Artificial intelligence in Australia needs t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "decoding str is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3e86d7c89ce5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmystring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: decoding str is not supported"
     ]
    }
   ],
   "source": [
    "str(mystring, 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
